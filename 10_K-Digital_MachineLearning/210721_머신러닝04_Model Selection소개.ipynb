{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 데이터 세트 / 테스트 데이터 세트 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 model_selection 모듈의 주요 기능\n",
    "- 학습 데이터와 테스트 데이터 세트 분리\n",
    "- 교차 검증 분할 및 평가\n",
    "- Estimator의 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터와 테스트 데이터 세트 분리\n",
    "- train_test_split() 함수 사용\n",
    "\n",
    "학습 데이터 세트\n",
    "- 머신러닝 알고리즘의 학습을 위해 사용\n",
    "- 데이터의 피처(속성)과 레이블(결정값) 모두 포함\n",
    "- 학습 데이터를 기반으로 머신러닝 알고리즘이 데이터 속성과 (피처)과 결정값을 (레이블)의 패턴을 인지하고 학습\n",
    "\n",
    "테스트 데이터 세트\n",
    "- 학습된 머신러닝 알고리즘 테스트용\n",
    "- 머신러능 알고리즘은 제공된 속성 데이터를 기반으로 결정값 예측\n",
    "- 학습 데이터와 별도의 세트로 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split() 함수 사용\n",
    "- train_test_split(iris_data, iris_label, test_size=0.3, random_state=11)\n",
    "- train_test_split(피처 데이터 세트, 레이블 데이터 세트, 테스트 데이터 세트 비율, 난수 발생값)\n",
    "- 피처 데이터 세트 : 피처(feature)만으로 된 데이터(numpy) [5.1, 3.5, 1.4, 0.2],...\n",
    "- 레이블 데이터 세트 : 레이블(결정 값) 데이터(numpy) [0 0 0 ... 1 1 1 .... 2 2 2]\n",
    "- 테스트 데이터 세트 비율 : 전체 데이터 세트 중 테스트 데이터 세트 비율 (0.3)\n",
    "- 난수 발생값 : 수행할 때마다 동일한 데이터 세트로 분리하기 위해 시드값 고정 (실습용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split() 반환값\n",
    "- X_train : 학습용 피처 데이터 세트 (feature)\n",
    "- X_test : 테스트용 피처 데이터 세트 (feature)\n",
    "- y_train : 학습용 레이블 데이터 세트 (target)\n",
    "- y_test : 테스트용 레이블 데이터 세트 (target)\n",
    "- feature : 대문자 X_\n",
    "- label(target) : 소문자 y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 학습 데이터/테스트 데이터 세트 분리 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "붓꽃 데이터 품종 예측\n",
    "1. 학습/테스트 데이터 세트로 분리하지 않고 예측\n",
    "2. 학습/테스트 데이터 세트로 분리하고 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 학습/테스트 데이터 세트로 분리하지 않고 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T04:25:32.349918Z",
     "start_time": "2021-07-21T04:25:32.336966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "# 1. 학습/테스트 데이터 세트로 분리하지 않고 예측\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "train_data = iris.data # 피처(속성)만으로 된 데이터\n",
    "train_label = iris.target # target 값(결정값(정답), 레이블 값)\n",
    "\n",
    "# 학습 수행 : 테스트 데이터 세트 분리하고 않고 사용\n",
    "# fit(학습용 피처 데이터, 학습용 target 데이터)\n",
    "dt_clf.fit(train_data, train_label)\n",
    "\n",
    "# 학습된 데이터 셋으로 예측 수행 : 테스트 데이터 세트 분리하지 않고 사용\n",
    "pred = dt_clf.predict(train_data)\n",
    "\n",
    "print('예측 정확도 : ', accuracy_score(train_label, pred))\n",
    "\n",
    "# 결과\n",
    "# 예측을 별도로 분리하지 않고 학습된 train_data로 했기 때문에\n",
    "# 결과가 1.0 (100%)로 출력됨 (잘못된 예측 방법!!!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터와 유사한 데이터로 테스트를 했다면  \n",
    "알고리즘이 안좋더라도 예측 정확도가 높을 수 있음 (신뢰성 떨어짐)  \n",
    "  \n",
    "알고리즘을 얼마나 잘 학습했는냐는  \n",
    "기존의 학습 데이터에는 포함되어 있지 않은 데이터 대해  \n",
    "얼마나 잘 예측할 수 있는냐와 밀접한 관계가 있음  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습/테스트 데이터 세트로 분리하고 예측 : sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T04:35:52.243944Z",
     "start_time": "2021-07-21T04:35:52.229731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9556\n"
     ]
    }
   ],
   "source": [
    "# 2. 학습/테스트 데이터 세트로 분리하고 예측\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "# 학습/테스트 데이터 세트 분리\n",
    "# 학습 데이터와 테스트 데이터 세트로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data,\n",
    "                                                    iris_data.target,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=121)\n",
    "\n",
    "# 학습 수행\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측 수행\n",
    "pred = dt_clf.predict(X_test)\n",
    "\n",
    "# 예측 정확도 출력\n",
    "print('예측 정확도 : {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### DataFrame/Series로 분할하기\n",
    "Numpy 뿐만 아니라 Pandas DataFrame/Series도 train_test_split() 사용해서 분할 가능  \n",
    "위에서 했던 2. 학습/테스트 데이터 세트로 분리하고 예측 : sklearn 과 결과는 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T04:40:19.758185Z",
     "start_time": "2021-07-21T04:40:19.731388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
       "0                  5.1               3.5  ...               0.2       0\n",
       "1                  4.9               3.0  ...               0.2       0\n",
       "2                  4.7               3.2  ...               0.2       0\n",
       "3                  4.6               3.1  ...               0.2       0\n",
       "4                  5.0               3.6  ...               0.2       0\n",
       "..                 ...               ...  ...               ...     ...\n",
       "145                6.7               3.0  ...               2.3       2\n",
       "146                6.3               2.5  ...               1.9       2\n",
       "147                6.5               3.0  ...               2.0       2\n",
       "148                6.2               3.4  ...               2.3       2\n",
       "149                5.9               3.0  ...               1.8       2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "iris_df['target'] = iris_data.target  # 타겟값 넣어주기\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T05:11:32.638594Z",
     "start_time": "2021-07-21T05:11:32.630622Z"
    }
   },
   "outputs": [],
   "source": [
    "# 피처 데이터 세트\n",
    "ftr_df = iris_df.iloc[:, :-1] # 마지막 컬럼 -1 까지 추출\n",
    "ftr_df\n",
    "\n",
    "# 레이블 데이터 세트 (target 값)\n",
    "tgt_df = iris_df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ftr_df,\n",
    "                                                    tgt_df,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=121)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T05:13:00.238204Z",
     "start_time": "2021-07-21T05:13:00.233919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      " <class 'pandas.core.frame.DataFrame'> \n",
      " <class 'pandas.core.series.Series'> \n",
      " <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train),'\\n', type(X_test),'\\n', type(y_train),'\\n', type(y_test))\n",
    "\n",
    "# X_train : 학습용 피처 데이터\n",
    "# X_test : 테스트용 피처 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T05:14:39.006014Z",
     "start_time": "2021-07-21T05:14:38.994129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9556\n"
     ]
    }
   ],
   "source": [
    "# 학습 / 예측 / 예측 정확도 출력\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "\n",
    "# 예측 정확도 출력\n",
    "print('예측 정확도 : {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 교차 검증 : K-Fold와 Stratified K-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습/테스트 데이터 세트 분리 시 문제점\n",
    "- 부적합 데이터 선별로 인한 알고리즘 성능 저하\n",
    "- 과적합 문제 발생 (overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T05:19:51.382181Z",
     "start_time": "2021-07-21T05:19:51.376535Z"
    }
   },
   "source": [
    "#### 과적합 (overfitting)\n",
    "모델이 학습 데이터에 과도하게 최적화되어 다른 데이터로 실제 예측을 수행할 경우 예측 성능이 과도하게 떨어지는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과적합 문제 발생\n",
    "고정된 학습 데이터와 테스트 데이터에만 최적의 성능을 발휘할 수 있도록 편향되게 모델을 유도하는 경향 발생  \n",
    "결국, 해당 테스트데이터에만 과적합되는 학습 모델이 만들어져서 다른 테스트용 데이터가 들어올 경우 성능 저하 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML은 데이터에 기반하고   데이터는 이상치, 분포도, 다양한 속성 값, 피처 중요도 등 ML 에 영향을 미치는 다양한 요소를 가지고 있음  \n",
    "특정 ML 알고리즘에 최적으로 동작할 수 있도록 데이터를 선별해서 학습한다면 실제 데이터 양식과 많은 차이가 있을 것이고  \n",
    "결국 성능 저하로 이어짐  \n",
    "  \n",
    "문제점 개성 ---> 교차 검증을 이용해서 다양한 학습 평가 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 검증\n",
    "데이터 편중을 막기 위해 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것  \n",
    "학습 후, 학습된 데이터로 여러 번 검증 수행  \n",
    "각 세트에서 수행한 평가 결과에 따라 하이퍼 파라미터 튜닝 등의 모델 최적화 쉽게 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML 모델의 성능 평가 프로세스\n",
    "- 교차 검증 기반으로 1차 평가 수행 후 최종적으로 테스트 데이터 세트에 적용해 평가\n",
    "- ML에 사용되는 데이터 세트를 세분화 해서 학습, 검증, 테스트 세트로 분리\n",
    "- 테스트 데이터 세트 외에 별도의 검증 데이터 세트를 둬서 최종 평가 이전에 학습된 모델을 다양하게 평가하는데 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 검증 방법\n",
    "1. K-폴드 교차 검증\n",
    "2. Stratified K 폴드 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# K-폴드 교차 검증\n",
    "K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행  \n",
    "가장 보편적으로 사용되는 교차 검증 방법임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K = 5 라면  \n",
    "5개의 폴드된 데이터 세트를 학습용과 검증용으로 변경하면서 5번 평가 수행 후  \n",
    "5개의 평균한 결과로 예측 성능 평가  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K 폴드 교차 검증 프로세스 구현을 위한 사이킷런 클래스\n",
    "1. K-Fold 클래스 : 폴드 세트로 분리하는 객체 생성\n",
    "    - kfold = KFold(n_splits=5)\n",
    "2. split() 메소드 : 폴드 데이터 세트로 분리\n",
    "    - kfold.split(features)\n",
    "    - 각 폴드마다 학습용, 검증용 데이터 추출하고 학습 및 예측 수행, 정확도 측정\n",
    "3. 최종 평균 정확도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-폴드 교차 검증 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T06:00:42.313797Z",
     "start_time": "2021-07-21T06:00:42.304244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기 : 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "print('붓꽃 데이터 세트 크기 :', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T06:00:43.571029Z",
     "start_time": "2021-07-21T06:00:43.565729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape # 150개 데이터, 피처 4개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold 교차검증으로 5개 폴드 세트로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T05:39:55.214683Z",
     "start_time": "2021-07-21T05:39:55.210569Z"
    }
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체 생성\n",
    "kfold = KFold(n_splits = 5)\n",
    "\n",
    "# 폴드 세트별로 정확도를 저장할 리스트 객체 생성\n",
    "cv_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T05:41:07.410098Z",
     "start_time": "2021-07-21T05:41:07.405482Z"
    }
   },
   "source": [
    "features : 150개 데이터  \n",
    "5개로 나누므로 학습용 데이터는 120, 검증용 데이터는 30  \n",
    "KFold 객체의 split() 메소드를 사용해서 폴드 데이터 세트로 분리    \n",
    "폴드별 학습용, 검증용 데이터 세트의 행 인덱스 반환 출력 확인하기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T05:43:51.558082Z",
     "start_time": "2021-07-21T05:43:51.548291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index :\n",
      " [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] \n",
      " test_index :\n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "train_index :\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] \n",
      " test_index :\n",
      " [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "train_index :\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] \n",
      " test_index :\n",
      " [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "train_index :\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] \n",
      " test_index :\n",
      " [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "train_index :\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] \n",
      " test_index :\n",
      " [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "# 폴드별 학습용, 검증용 데이터 세트의 행 인덱스 확인하기\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    print('train_index :\\n', train_index, '\\n', 'test_index :\\n', test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 다음에 어떤 순서로 진행할 것인가...  \n",
    "1. 각 폴드 별 학습용, 검증용 데이터 추출하기\n",
    "2. 학습 및 예측하기\n",
    "3. 정확도 측정하기 -> 리스트에 저장\n",
    "4. 평균 검증 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T06:55:17.436525Z",
     "start_time": "2021-07-21T06:55:17.414746Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 교차검증 정확도 : 0.0 \n",
      " 학습 데이터 크기 : 100 \n",
      " 검증 데이터 크기 : 50 \n",
      "\n",
      "1) 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "----------------------------------------\n",
      "2) 교차검증 정확도 : 0.0 \n",
      " 학습 데이터 크기 : 100 \n",
      " 검증 데이터 크기 : 50 \n",
      "\n",
      "2) 검증 세트 인덱스 : [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "----------------------------------------\n",
      "3) 교차검증 정확도 : 0.0 \n",
      " 학습 데이터 크기 : 100 \n",
      " 검증 데이터 크기 : 50 \n",
      "\n",
      "3) 검증 세트 인덱스 : [100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "----------------------------------------\n",
      "※ 평균 검증 정확도 : 0.3222222222222222\n"
     ]
    }
   ],
   "source": [
    "# 반복문이라서 단순 횟수 증가하는 생성값 만들어줌\n",
    "n_iter = 0\n",
    "\n",
    "# K 가 5 이므로 5번 반복\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # 1) 각 폴드 별 학습용, 검증용 데이터 확인하기\n",
    "    X_train, X_test = features[train_index], features[test_index]  # 피처 데이터\n",
    "    y_train, y_test = label[train_index], label[test_index]  # 레이블 (타깃) 데이터\n",
    "\n",
    "    # 2) 학습 및 예측 수행\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "\n",
    "    n_iter += 1\n",
    "\n",
    "    # 3) 반복할 때마다 정확도 측정\n",
    "    accracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]  # X_train.shpae : (120, 4) [0]이라 120만 나옴\n",
    "    test_size = X_test.shape[0]  # X_test.shpae : (30, 4) [0]이라 30만 나옴\n",
    "\n",
    "    print('{0}) 교차검증 정확도 : {1} \\n 학습 데이터 크기 : {2} \\n 검증 데이터 크기 : {3} \\n'.format(n_iter, accracy, train_size, test_size))\n",
    "    print('{0}) 검증 세트 인덱스 : {1}'.format(n_iter, test_index))\n",
    "    print('----------------------------------------')\n",
    "\n",
    "    # 리스트에 저장하기\n",
    "    cv_accuracy.append(accracy)\n",
    "\n",
    "# 4) 개별 정확도를 합하여 평균 정확도 계산\n",
    "print('※ 평균 검증 정확도 :', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Stratified K 폴드 교차 검증\n",
    "\n",
    "**불균형한 분포도**를 가진 레이블 (결정 클래스) 데이터 집합을 위한 K폴드 방식임  \n",
    "데이터 분포도가 불균형하게 퍼져있을 때, 분산되어 있을 때 사용함  \n",
    "예를들어 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한 쪽으로 치우친 경우  \n",
    "**학습 데이터와 검증 데이터 세트가 가지는 레이블 분포도가 유사하도록 검증 데이터 추출**  \n",
    "원본 데이터의 레이블 분포도를 먼저 고려한 뒤, 이 분포와 동일하게 학습 데이터와 검증 데이터를 분배함  \n",
    "KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결하는 방법임  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified K 폴드 교차 검증 방법이 사용되는 예시\n",
    "- 대출 사기 데이터 예측\n",
    "- 데이터 세트 : 1억건\n",
    "- feature 수십 개\n",
    "- 대출 사기 여부를 뜻하는 레이블 : 대출사기 1, 정상 대출 0\n",
    "- 대출 사기 건수가 매우 적음 약 1000건 (전체의 0.00001%)\n",
    "\n",
    "이렇게 작은 비율로 1 레이블 값이 있다면 K폴드 랜덤하게 학습/테스트 데이터 세트의 인덱스를 고르더라도 레이블 값인 0과 1 비율을 제대로 반영하지 못하는 경우가 쉽게 발생함  \n",
    "즉, 레이블 값으로 1이 특정 개별 반복별 학습/테스트 데이터 세트에는 상대적으로 많이 들어 있어도 다른 반복 학습/테스트 데이터 세트에는 적게 포함되어 있을 수 있음\n",
    "  \n",
    "그러나 대출 사기 레이블이 1인 레코드는 비록 건수는 적지만 알고리즘이 대출 사기를 예측하기 위한 중요한 피처값을 가지고 있음! 때문에 매우 중요한 데이터 세트임  \n",
    "대출 사기 레이블 값의 분포를 원본 데이터의 분포와 유사하게 학습/테스트 데이터 세트에서도 유지하는 게 매우 중요함  \n",
    "  \n",
    "따라서 원본 데이터의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습과 검증 데이터 세트를 분배하는 방식인 Stratified K 폴드 교차 검증 방법을 사용해서 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K 폴드 교차 검증 예제\n",
    "먼저 K폴드 문제점을 확인하고, 사이킷런의 Stratified K 폴드 교차 검증 방법으로 개선  \n",
    "붓꽃 데이터 세트를 데이터 프레임으로 생성하고 레이블 값의 분포도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K 폴드 교차 검증을 그냥 K폴드로 하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T06:33:38.327173Z",
     "start_time": "2021-07-21T06:33:38.294199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sepal length (cm) sepal width (cm) petal length (cm) petal width (cm)  lable\n",
       "0               NaN              NaN               NaN              NaN      0\n",
       "1               NaN              NaN               NaN              NaN      0\n",
       "2               NaN              NaN               NaN              NaN      0\n",
       "3               NaN              NaN               NaN              NaN      0\n",
       "4               NaN              NaN               NaN              NaN      0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(data = iris_data, columns=iris_data.feature_names)\n",
    "iris_df['lable'] = iris_data.target\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T06:34:57.802956Z",
     "start_time": "2021-07-21T06:34:57.793078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: lable, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 레이블 값 개수 확인\n",
    "iris_df['lable'].value_counts()\n",
    "\n",
    "# 결과 : 레이블 값은 0, 1, 2 가 모두 50개로 동일함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T06:41:27.598853Z",
     "start_time": "2021-07-21T06:41:27.577073Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "1    50\n",
      "Name: lable, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 0    50\n",
      "Name: lable, dtype: int64\n",
      "-----------------------------\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    50\n",
      "0    50\n",
      "Name: lable, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    50\n",
      "Name: lable, dtype: int64\n",
      "-----------------------------\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    50\n",
      "0    50\n",
      "Name: lable, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    50\n",
      "Name: lable, dtype: int64\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3개의 폴드 세트 생성\n",
    "kfold = KFold(n_splits=3)\n",
    "\n",
    "# 반복문이라서 단순 횟수 증가하는 생성값 만들어줌\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    \n",
    "    label_train = iris_df['lable'].iloc[train_index]\n",
    "    label_test = iris_df['lable'].iloc[test_index]\n",
    "    \n",
    "    print('교차 검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n', label_test.value_counts())\n",
    "    print('-----------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "교차 검증 할 때마다 3개의 폴드 세트로 만들어지는 학습 레이블과 검증 레이블이 완전히 다른 값으로 추출되었음  \n",
    "\n",
    "첫 번째 교차 검증  \n",
    "학습 레이블의 1, 2 값이 각 50개 나옴  \n",
    "검증 레이블에서는 0의 값이 50개 나옴  \n",
    "-> 학습 레이블은 1, 2 밖에 없으므로 0의 경우를 전혀 학습하지 못함 검증 레이블은 0밖에 없으므로 학습 모델은 절대 0을 예측하지 못함  \n",
    "  \n",
    "이런 유형으로 교차 검증 데이터 세트를 분할하면 검증 예측 정확도는 0이 됨  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K 폴드 교차 검증 방식으로 iris 데이터 교차 검증\n",
    "Stratified KFold 클래스 사용  \n",
    "동일한 데이터 분할을 StratifiedKFold로 수행하고 학습/검증 레이블 데이터 분포도 확인  \n",
    "단 하나의 큰 차이는 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에 split() 메서드 인자로 피처 데이터와 함께 반드시 레이블 데이터 반드시 필요하다는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T07:12:23.824494Z",
     "start_time": "2021-07-21T07:12:23.804219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: lable, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: lable, dtype: int64\n",
      "-----------------------------\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: lable, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: lable, dtype: int64\n",
      "-----------------------------\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: lable, dtype: int64\n",
      "검증 레이블 데이터 분포 : \n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: lable, dtype: int64\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# 동일한 데이터 분할을 StratifiedKFold로 수행하고 학습/검증 레이블 데이터 분포도 확인  \n",
    "# 단 하나의 큰 차이는 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에 split() 메서드 인자로 피처 데이터와 함께 반드시 레이블 데이터 반드시 필요하다는 것\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 3)  # 폴드 세트 3개\n",
    "n_iter = 0\n",
    "\n",
    "# 레이블 데이터 세트도 반드시 인자로 사용\n",
    "for train_index, test_index in skfold.split(iris_df, iris_df['lable']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['lable'].iloc[train_index]\n",
    "    label_test = iris_df['lable'].iloc[test_index]\n",
    "    \n",
    "    print('교차 검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 : \\n', label_test.value_counts())\n",
    "    print('-----------------------------')\n",
    "    \n",
    "# 출력 결과\n",
    "# 학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당\n",
    "# 학습 레이블 : 0, 1, 2 - 33, 33, 34\n",
    "# 검증 레이블 : 0, 1, 2 - 17, 17, 16\n",
    "\n",
    "# 이렇게 분할 되어야 레이블 값이 0, 1, 2 모두 학습할 수 있고 이에 기반해서 검증 수행 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력 결과\n",
    "학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당  \n",
    "학습 레이블 : 0, 1, 2 - 33, 33, 34  \n",
    "검증 레이블 : 0, 1, 2 - 17, 17, 16  \n",
    "  \n",
    "이렇게 분할 되어야 레이블 값이 0, 1, 2 모두 학습할 수 있고 이에 기반해서 검증 수행 가능  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T07:18:52.837170Z",
     "start_time": "2021-07-21T07:18:52.812779Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 교차검증 정확도 : 0.98 \n",
      " 학습 데이터 크기 : 100 \n",
      " 검증 데이터 크기 : 50 \n",
      "\n",
      "1) 검증 세트 인덱스 : \n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "--------------------------------------------\n",
      "2) 교차검증 정확도 : 0.94 \n",
      " 학습 데이터 크기 : 100 \n",
      " 검증 데이터 크기 : 50 \n",
      "\n",
      "2) 검증 세트 인덱스 : \n",
      " [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "--------------------------------------------\n",
      "3) 교차검증 정확도 : 0.98 \n",
      " 학습 데이터 크기 : 100 \n",
      " 검증 데이터 크기 : 50 \n",
      "\n",
      "3) 검증 세트 인덱스 : \n",
      " [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "--------------------------------------------\n",
      "※ 교차 검증별 정확도 : [0.98 0.94 0.98]\n",
      "※ 평균 검증 정확도 : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Stratified KFold 방식으로 붓꽃 데이터 교차 검증\n",
    "# Stratified KFold 클래스 사용\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "# StratifiedKFold의 split() 호출할 때 피처 데이터와 함께 반드시 레이블 데이터 세트도 추가 입력\n",
    "for train_index, test_index in skfold.split(features, label):   # 여기서  label 데이터 셋을 넣는 점이 다르다\n",
    "    # 1) 각 폴드 별 학습용, 검증용 데이터 확인하기\n",
    "    X_train, X_test = features[train_index], features[test_index]  # 피처 데이터\n",
    "    y_train, y_test = label[train_index], label[test_index]  # 레이블 (타깃) 데이터\n",
    "\n",
    "    # 2) 학습 및 예측 수행\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "\n",
    "    n_iter += 1\n",
    "\n",
    "    # 3) 반복할 때마다 정확도 측정\n",
    "    accracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]  # X_train.shpae : (120, 4) [0]이라 120만 나옴\n",
    "    test_size = X_test.shape[0]  # X_test.shpae : (30, 4) [0]이라 30만 나옴\n",
    "\n",
    "    print('{0}) 교차검증 정확도 : {1} \\n 학습 데이터 크기 : {2} \\n 검증 데이터 크기 : {3} \\n'.format(n_iter, accracy, train_size, test_size))\n",
    "    print('{0}) 검증 세트 인덱스 : \\n {1}'.format(n_iter, test_index))\n",
    "    print('--------------------------------------------')\n",
    "\n",
    "    # 리스트에 저장하기\n",
    "    cv_accuracy.append(accracy)\n",
    "\n",
    "# 4) 개별 정확도를 합하여 평균 정확도 계산\n",
    "print('※ 교차 검증별 정확도 :', np.round(cv_accuracy,4))\n",
    "print('※ 평균 검증 정확도 :', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stratified K 폴드 교차 검증 정리\n",
    "원본 데이터의 레이블 분포도 특성을 반영한 학습 및 검증 데이터 세트를 만들 수 있으므로  \n",
    "왜곡된 레이블 데이터 세트에서는 반드시  Stratified K 폴드를 이용해서 교차 검증해야 함  \n",
    "일반적으로 분류(Classification)에의 교차 검증은 K폴드가 아니라  Stratified K 폴드로 분할되어야 함  \n",
    "회귀(Regression)에서  Stratified K 폴드가 지원되지 않음  \n",
    "이유는 회귀의 결정 값은 이산값 형태의 레이블이 아니라 연속된 숫자값이기 때문에 결정값별로 분포를 정하는 의미가 없기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 사이킷런 API를 사용해 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 검증 (Cross Validation) 과정\n",
    "1. 폴드 세트 설정\n",
    "2. for 문에서 반복적으로 학습 및 검증 데이터 추출하고 학습/예측 수행\n",
    "3. 폴드 세트 별로 예측 성능을 평균하여 최종 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 검증을 보다 간편하게 해준 사이킷런 API\n",
    "- cross_val_score() 함수\n",
    "- (1) ~ (3) 단계의 교차 검증 과정을 한꺼번에 수행\n",
    "- 내부에서 Estimator를 학습(fit), 예측(predict), 평가(evaluation) 시켜주므로 간단하게 교차 검증 수행 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_score() 주요 파라미터\n",
    "- estimator : Classifier 또는 Regressor (분류 또는 회귀)\n",
    "- X : 피처 데이터 세트\n",
    "- y : 레이블 데이터 세트\n",
    "- scoring : 예측 성능 평가 지표\n",
    "- cv : 교차 검증 폴드 수\n",
    "- cross_val_score(dt_clf, data, label, scoring='accuracy‘, cv=3)\n",
    "- cv로 지정된 횟수 만큼 scoring 파라미터로 지정된 평가 지표로 평가 결과값을 배열로 반환\n",
    "- 일반적으로 평가 결과값 평균을 평가 수치로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T07:37:53.771692Z",
     "start_time": "2021-07-21T07:37:53.747844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 : [0.98 0.94 0.98]\n",
      "평균 검증 정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "# cross_val_score()\n",
    "# 교차 검증 폴드 수 : 3\n",
    "# 성능 평가 지표 : accuracy (정확도)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "labela = iris_data.target\n",
    "\n",
    "# 성능 지표 : accuracy(정확도), 교차 검증 폴드 수 : 3\n",
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "print('교차 검증별 정확도 :', scores)\n",
    "print('평균 검증 정확도 :', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_val_score() 수행 결과\n",
    "앞 예제 StratifiedKFold를 이용해 붓꽃 데이터 교차 검증 결과와 동일함  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 하이퍼 파라미터 (Hyper Parameter)\n",
    "모델링할 때 사용자가 직접 세팅해 주는 값  \n",
    "여러 하이퍼 파라미터를 순차적으로 변경하면서 최고 성능을 가지는 파아미터 조합을 찾을 수 있음  \n",
    "예) max_depth, min_samples_split, iteration 등  \n",
    "머신러닝 알고리즘을 구성하는 주요 구성 요소임  \n",
    "이 값들을 조정해서 알고리즘의 예측 성능을 개선할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV 클래스\n",
    "**교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에**  \n",
    "사이킷런에서는 GridSearchCV 클래스를 이용해서 Classifier나 Regressor 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 최적의 파라미터를 편리하게 도출할 수 있는 방법을 제공함  \n",
    "Grid는 격자라는 의미임 촘촘하게 파라미터를 입력하면서 테스트 하는 방식\n",
    "  \n",
    "#### 최적의 하이퍼 파라미터를 찾는 방법  \n",
    "머신러닝 알고리즘의 여러 하이퍼 파라미터를 순차적으로 변경하면서 최고 성능을 가지는 파라미터를 찾으려면 파아미터의 집합을 만들어서 순차적으로 적용하면서 최적화 수행  \n",
    "성능이 최고일 때의 하이퍼 파라미터가 최적의 파라미터가 됨  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV 클래스 생성자의 주요 파라미터\n",
    "- estimator : classifier, regressor, peipeline\n",
    "- param_grid : key + 리스트 값을 가지는 딕셔너리 (estimator 튜닝을 위한 하이퍼 파라미터 )\n",
    "  - key: 파라미터명, 리스트값:파라미터 값\n",
    "- scoring : 예측 성능을 측정할 평가 방법\n",
    "  - 성능 평가 지표를 지정하는 문자열 (예: 정확도인 경우 'accuracy')\n",
    "- cv : 교차 검증을 위해 분할되는 학습/테스트 세트의 개수\n",
    "- refit : 최적의 하이퍼 파라미터를 찾은 뒤\n",
    "  - 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습 여부\n",
    "  - 디폴트 : True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
