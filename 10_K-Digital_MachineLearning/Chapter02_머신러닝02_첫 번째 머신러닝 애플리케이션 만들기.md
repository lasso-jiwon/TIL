# 첫 번째 머신러닝 모델

## 사이킷런을 이용하여 붓꽃 만들기

사이킷런을 이용한 붓꽃 데이터 분류
- 붓꽃 데이터 세트를 이용해서 붓꽃의 품종을 분류 (Classifcation)

붓꽃 데이터 세트
- sklearn.datasets에 들어 있음 (내장 데이터 세트)
- load_iris() 통해 로드해서 사용
- 머신러닝 각 분에서 알고리즘 측정하기 위해 기본 자료로 다양하게 활용
- 4가지 속성(피처)를 가진 3가지 붓꽃 품종의 각 50개 샘플 포함

붓꽃 데이터 분류  
  
분류(Classification)
- 대표적인 지도학습 방법
- 학습을 위한 다양한 피처(속성)와 분류 결정값인 레이블(품종) 데이터로 모델을 학습한 후
- 별도의 데스트 데이터 세트에서 레이블 (품종) 예측
- 즉, 학습 데이터로 학습한 후, 테스트 데이터의 데이터를 보고 어떤 품종인 예측하는 것

학습 데이터 : 학습용 데이터 세트
테스트 데이터 : 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트

용어 정리  
피처 (Feature) : 데이터 세트 속성
    - feature_names : sepal length, sepal width, petal length, petal width
    
레이블 (Label)
- 품종 (setosa, versicolr, virginica)
- 결정값 (주어진 정답)
- 타깃값 (target) : 예측해야 할 값
- target (숫자): 0, 1, 2
- target_names : setosa, versicolr, virginica
- 레이블 = 결정값(정답) = 타깃값

붓꽃 데이터 예측 프로세스  
(1) 데이터 세트 분리 : 학습 데이터 / 테스트 데이터 세트  
(2) 모델 학습 : 학습 데이터 세트 기반으로 ML 알고리즘을 적용하여 모델 학습  
(3) 예측 수행 : 학습된 ML 모델을 이용해서 테스트 데이터의 분류 예측 (즉, 붓꽃 품종 예측)  
(4) 평가 : 예측된 결과값과 테스트 데이터의 실제 결과값과 비교해서 ML 모델 성능 평가

## 사이킷런을 이용하여 붓꽃 데이터 품종 예측 예제


```python
# 사이킷런 버전 확인
import sklearn
print(sklearn.__version__)
```

    0.23.2


### 붓꽃 예측을 위한 사이킷런 필요 모듈 로딩


```python
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
```

사이킷런 패키지 모듈
* 명명규칙 : 모듈명은 sklearn으로 시작
* sklearn.datasets : 사이킷런에서 자체적으로 제공하는 데이터 세트를 생성하는 모듈 모임
* sklearn.tree : 트리 기반 ML 알고리즘을 구현한 클래스 모임
* sklearn.model_selection : 학습 데이터와 검증 데이터, 예측 데이터로 데이터를 분리하거나  
    최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈의 모임
    - 하이퍼 파라미터 : 머신러닝 알고리즘별로 최적의 학습을 위해 직접 입력하는 파라미터
        - 머신러닝 알고리즘의 성능 튜닝에 사용

### 데이터 세트 로딩


```python
import pandas as pd
```


```python
# 붓꽃 데이터 세트를 로딩합니다
iris = load_iris()
iris_data = iris.data
```


```python
# iris.target : 붓꽃 데이터 세트에서 
# 레이블(결정값) 데이터 numpy 가지고 있음 (숫자)
# 레이블 = 결정값 = 정답 (품종을 숫자로 표현)

iris_label = iris.target
print('iris target 값 :', iris_label)
print('iris target 명 :', iris.target_names)
```

    iris target 값 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
     0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
     1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
     2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
     2 2]
    iris target 명 : ['setosa' 'versicolor' 'virginica']



```python
# 붓꽃 데이터 DataFrame으로 변환
iris_df = pd.DataFrame(data = iris_data, columns=iris.feature_names)
iris_df.head(3)

# sepal : 꽃밭침
# petal : 꽃잎
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>
</div>



### 학습 데이터와 테스트 데이터 세트로 분리

train_test_split() 함수 사용
- train_test_split(iris_data, iris_label, test_size=0.3, random_state=11)
- train_test_split(피처 데이터 세트, 레이블 데이터 세트, 테스트 데이터 세트 비율, 난수 발생값)
- 피처 데이터 세트 : 피처(feature)만으로 된 데이터(numpy) [5.1, 3.5, 1.4, 0.2],...
- 레이블 데이터 세트 : 레이블(결정 값) 데이터(numpy) [0 0 0 ... 1 1 1 .... 2 2 2]
- 테스트 데이터 세트 비율 : 전체 데이터 세트 중 테스트 데이터 세트 비율 (0.3)
- 난수 발생값 : 수행할 때마다 동일한 데이터 세트로 분리하기 위해 시드값 고정 (실습용)

train_test_split() 반환값
- X_train : 학습용 피처 데이터 세트 (feature)
- X_test : 테스트용 피처 데이터 세트 (feature)
- y_train : 학습용 레이블 데이터 세트 (target)
- y_test : 테스트용 레이블 데이터 세트 (target)
- feature : 대문자 X_
- label(target) : 소문자 y_


```python
# 학습 데이터와 테스트 데이터 세트로 분리
X_train, X_test, y_train, y_test = train_test_split(iris_data,
                                                    iris_label,
                                                    test_size=0.2,
                                                    random_state=121)
```


```python
X_train # 학습용 피처 데이터 세트 (feature)
```




    array([[6.7, 3.1, 4.7, 1.5],
           [7.7, 2.6, 6.9, 2.3],
           [5.2, 3.4, 1.4, 0.2],
           [5. , 3.5, 1.6, 0.6],
           [6.4, 2.9, 4.3, 1.3],
           [7.2, 3.6, 6.1, 2.5],
           [5.3, 3.7, 1.5, 0.2],
           [5.7, 3.8, 1.7, 0.3],
           [5.4, 3.4, 1.7, 0.2],
           [6.1, 2.6, 5.6, 1.4],
           [6.3, 2.7, 4.9, 1.8],
           [6. , 3. , 4.8, 1.8],
           [6.4, 3.1, 5.5, 1.8],
           [5.1, 3.8, 1.5, 0.3],
           [4.9, 2.5, 4.5, 1.7],
           [6.3, 2.8, 5.1, 1.5],
           [6.8, 3.2, 5.9, 2.3],
           [4.8, 3.4, 1.9, 0.2],
           [6.3, 2.5, 4.9, 1.5],
           [5. , 3.5, 1.3, 0.3],
           [5.2, 3.5, 1.5, 0.2],
           [4.4, 3. , 1.3, 0.2],
           [5.7, 4.4, 1.5, 0.4],
           [6.1, 3. , 4.6, 1.4],
           [6.7, 3. , 5. , 1.7],
           [5. , 3.4, 1.6, 0.4],
           [6.5, 3. , 5.2, 2. ],
           [6.7, 3.3, 5.7, 2.5],
           [5. , 2.3, 3.3, 1. ],
           [5.4, 3.4, 1.5, 0.4],
           [4.4, 3.2, 1.3, 0.2],
           [6.2, 2.9, 4.3, 1.3],
           [5.1, 3.5, 1.4, 0.3],
           [6.7, 2.5, 5.8, 1.8],
           [6.8, 3. , 5.5, 2.1],
           [4.6, 3.6, 1. , 0.2],
           [4.8, 3.4, 1.6, 0.2],
           [7.3, 2.9, 6.3, 1.8],
           [6.7, 3.3, 5.7, 2.1],
           [6.1, 2.8, 4.7, 1.2],
           [5.8, 2.8, 5.1, 2.4],
           [5.9, 3. , 5.1, 1.8],
           [6.3, 3.3, 4.7, 1.6],
           [5.4, 3. , 4.5, 1.5],
           [7.7, 2.8, 6.7, 2. ],
           [5.8, 2.7, 4.1, 1. ],
           [6.4, 2.8, 5.6, 2.1],
           [5.6, 2.5, 3.9, 1.1],
           [5.1, 3.8, 1.9, 0.4],
           [6.2, 2.8, 4.8, 1.8],
           [4.7, 3.2, 1.3, 0.2],
           [5.5, 2.4, 3.8, 1.1],
           [5.9, 3. , 4.2, 1.5],
           [7.2, 3.2, 6. , 1.8],
           [5.5, 2.4, 3.7, 1. ],
           [4.9, 3.6, 1.4, 0.1],
           [5.7, 2.8, 4.1, 1.3],
           [5.8, 2.7, 5.1, 1.9],
           [6.7, 3. , 5.2, 2.3],
           [5.7, 2.5, 5. , 2. ],
           [4.9, 3.1, 1.5, 0.1],
           [6.3, 3.3, 6. , 2.5],
           [5.5, 4.2, 1.4, 0.2],
           [6.7, 3.1, 5.6, 2.4],
           [7.7, 3. , 6.1, 2.3],
           [5. , 3.2, 1.2, 0.2],
           [5.1, 3.5, 1.4, 0.2],
           [5.6, 2.8, 4.9, 2. ],
           [4.3, 3. , 1.1, 0.1],
           [6.1, 2.8, 4. , 1.3],
           [6.5, 3. , 5.8, 2.2],
           [5.8, 2.7, 5.1, 1.9],
           [4.8, 3. , 1.4, 0.1],
           [6.1, 3. , 4.9, 1.8],
           [4.9, 3. , 1.4, 0.2],
           [6.1, 2.9, 4.7, 1.4],
           [5. , 3.4, 1.5, 0.2],
           [6.3, 2.9, 5.6, 1.8],
           [5.4, 3.9, 1.3, 0.4],
           [7.7, 3.8, 6.7, 2.2],
           [5.6, 3. , 4.1, 1.3],
           [4.8, 3. , 1.4, 0.3],
           [6.4, 2.8, 5.6, 2.2],
           [5. , 3.6, 1.4, 0.2],
           [5.5, 3.5, 1.3, 0.2],
           [6.5, 3.2, 5.1, 2. ],
           [4.8, 3.1, 1.6, 0.2],
           [6.8, 2.8, 4.8, 1.4],
           [7.2, 3. , 5.8, 1.6],
           [6.3, 2.3, 4.4, 1.3],
           [6. , 2.2, 5. , 1.5],
           [5.8, 4. , 1.2, 0.2],
           [5.8, 2.7, 3.9, 1.2],
           [6.2, 2.2, 4.5, 1.5],
           [6.9, 3.1, 5.4, 2.1],
           [5.4, 3.7, 1.5, 0.2],
           [7.4, 2.8, 6.1, 1.9],
           [6.4, 3.2, 4.5, 1.5],
           [6.9, 3.2, 5.7, 2.3],
           [5.6, 2.7, 4.2, 1.3],
           [6.5, 3. , 5.5, 1.8],
           [5.7, 2.8, 4.5, 1.3],
           [4.5, 2.3, 1.3, 0.3],
           [7.6, 3. , 6.6, 2.1],
           [5.1, 3.7, 1.5, 0.4],
           [5.1, 3.4, 1.5, 0.2],
           [6.6, 3. , 4.4, 1.4],
           [4.9, 2.4, 3.3, 1. ],
           [6.9, 3.1, 4.9, 1.5],
           [4.6, 3.1, 1.5, 0.2],
           [6.5, 2.8, 4.6, 1.5],
           [5. , 2. , 3.5, 1. ],
           [4.9, 3.1, 1.5, 0.2],
           [5.1, 3.8, 1.6, 0.2],
           [5.7, 2.9, 4.2, 1.3],
           [6. , 2.7, 5.1, 1.6],
           [6.7, 3.1, 4.4, 1.4],
           [5.7, 3. , 4.2, 1.2],
           [4.4, 2.9, 1.4, 0.2],
           [5.6, 3. , 4.5, 1.5]])




```python
X_test # 테스트용 피처 데이터 세트 (feature)
```




    array([[7. , 3.2, 4.7, 1.4],
           [6.2, 3.4, 5.4, 2.3],
           [6. , 3.4, 4.5, 1.6],
           [4.6, 3.4, 1.4, 0.3],
           [5.2, 4.1, 1.5, 0.1],
           [5.8, 2.6, 4. , 1.2],
           [5.6, 2.9, 3.6, 1.3],
           [5.7, 2.6, 3.5, 1. ],
           [5.2, 2.7, 3.9, 1.4],
           [6.9, 3.1, 5.1, 2.3],
           [5.9, 3.2, 4.8, 1.8],
           [5.5, 2.3, 4. , 1.3],
           [6.6, 2.9, 4.6, 1.3],
           [4.6, 3.2, 1.4, 0.2],
           [4.7, 3.2, 1.6, 0.2],
           [6.3, 3.4, 5.6, 2.4],
           [6. , 2.2, 4. , 1. ],
           [5. , 3. , 1.6, 0.2],
           [6.4, 3.2, 5.3, 2.3],
           [5.4, 3.9, 1.7, 0.4],
           [6.4, 2.7, 5.3, 1.9],
           [6.3, 2.5, 5. , 1.9],
           [6. , 2.9, 4.5, 1.5],
           [5.1, 2.5, 3. , 1.1],
           [5.5, 2.6, 4.4, 1.2],
           [5.5, 2.5, 4. , 1.3],
           [5. , 3.3, 1.4, 0.2],
           [5.1, 3.3, 1.7, 0.5],
           [7.9, 3.8, 6.4, 2. ],
           [7.1, 3. , 5.9, 2.1]])




```python
y_train # 학습용 레이블 데이터 세트 (target)
```




    array([1, 2, 0, 0, 1, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 1, 0, 0, 0,
           0, 1, 1, 0, 2, 2, 1, 0, 0, 1, 0, 2, 2, 0, 0, 2, 2, 1, 2, 2, 1, 1,
           2, 1, 2, 1, 0, 2, 0, 1, 1, 2, 1, 0, 1, 2, 2, 2, 0, 2, 0, 2, 2, 0,
           0, 2, 0, 1, 2, 2, 0, 2, 0, 1, 0, 2, 0, 2, 1, 0, 2, 0, 0, 2, 0, 1,
           2, 1, 2, 0, 1, 1, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 0, 1, 1, 1, 0,
           1, 1, 0, 0, 1, 1, 1, 1, 0, 1])




```python
y_test # 테스트용 레이블 데이터 세트 (target)
```




    array([1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 1, 0, 2, 0, 2, 2,
           1, 1, 1, 1, 0, 0, 2, 2])



## 학습 데이터 세트로 학습 수행 / 예측 수행

ML 알고리즘으로 의사결정 트리 알고리즘을 이용해서 학습과 예측 수행  
DecisionTreeClassifier 클래스의 fit()/predict() 메소드 사용
 
fit() : 학습 (학습용 데이터 사용)  
    - fit(학습용 피처 데이터 세트, 학습용 레이블(정답) 데이터 세트)

predict() : 예측 수행  
    - predict(테스트용 피처 데이터 세트)


```python
# DecisionTreeClassifier 객체 생성
dt_clf = DecisionTreeClassifier(random_state=11)

# 학습 수행
dt_clf.fit(X_train, y_train)  # 학습용 피처 데이터, 학습용 레이블(정답) 데이터
```




    DecisionTreeClassifier(random_state=11)



### 테스트 데이터 세트로 예측(Predict) 수행


```python
# 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이트 세트로 예측 수행
pred = dt_clf.predict(X_test)  # 테스트용 피처 데이터
```


```python
pred  # 예측한 값
```




    array([2, 2, 1, 1, 2, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0,
           0, 1, 0, 0, 2, 1, 0, 1])




```python
y_test  # 테스트용 레이블 데이터 세트
```




    array([2, 2, 2, 1, 2, 0, 1, 0, 0, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 0,
           0, 1, 0, 0, 2, 1, 0, 1])




```python
# 실제 데이터 레이블 값과 예측한 값 비교
print(pred)
print(y_test)

# 결과
# 30개 중 2개만 예측이 빗나갔고 28개 정확하게 예측함
# 28/30 = 0.9333
```

    [2 2 1 1 2 0 1 0 0 1 1 1 1 2 2 0 2 1 2 2 1 0 0 1 0 0 2 1 0 1]
    [2 2 2 1 2 0 1 0 0 1 2 1 1 2 2 0 2 1 2 2 1 0 0 1 0 0 2 1 0 1]


### 예측 정확도 평가

예측 결과를 기반으로 의사 결정 트리 기반의 DecisionTreeClassifier 예측 성능 평가  
머신러닝 모델의 여러 성능 평가 방법 중 정확도 측정 (Accuracy)  
정확도 : 예측 결과 실제 레이블 값과 얼마나 정확하게 맞는지 평가하는 지표  
예측한 붓꽃 품종과 실제 테스트 데이터 세트의 붓꽃 품종이 얼마나 일치하는지 확인  
  
정확도 측정을 위해 사이킷런에서 제공하는 `accuracy_score()`함수 사용  
`accuracy_score(실제 테스트용 레이블 데이터 세트, 예측된 레이블 데이터 세트)`


```python
# 예측 정확도 확인
from sklearn.metrics import accuracy_score

print('예측 정확도 :{0:.4f}'.format(accuracy_score(y_test, pred)))

# 30개 중에서 28개 정확하게 예측함 : 28/33 = 0.9333
```

    예측 정확도 :0.9333


___
# 붓꽃 데이터 품종 예측 프로세스 정리

1. 데이터 준비 (데이터 로드 / 데이터 확인) : `load_iris()` 사용  
2. 학습 데이터와 테스트 데이터 세트 분리 : `train_test_split()`사용  
3. 학습 및 예측 수행  : DecisionTreeClassifier 클래스의 `fit()` / `predict()` 사용  
- `fit()` : 학습용 데이터를 사용해서 학습  
- `predict()` : 테스트용 피처 데이터 사용해서 예측  
4. 예측 정확도 평가 : `accuracy_score()` 함수 사용   
- 실제 테스트용 레이블 데이터 세트와 예측된 레이블 데이터 세트 비교 (실제값 vs 예측값)  
- 예측 정확도 측정
